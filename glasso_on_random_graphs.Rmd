---
title: "Experimentation with glasso package for sparse estimation of random matrices and Markov chains"
output: html_document
---

Include necessary packages

```{r setup, include=FALSE}
library(clusterGeneration)
library(glasso)
library(Matrix)
library(pracma)
```


# Experiment on random sparse graphs

Here, we test glasso on some random sparse graphs and draw ROC curves to select an appropriate value for the parameter rho.



Generate Sigma and Theta (Sigma^{-1}) corresponding to a graph of size p and with a sparsity_level % non null coefficients in Theta. We use the fact that a diagonally dominant matrix is positive, and add 0.5 on the diagonal in order to make the smallest eigenvalue >0.

```{r}
# Generate a sparse positive semidefinite matrix
genThetaSigma <-function(p, sparsity_level=0.25){
  sigma <- as.matrix(rsparsematrix(p,p,sparsity_level))
  sigma <- sigma + t(sigma)
  diag <- colSums(abs(sigma),dims = 1)
  diag(sigma) <- diag(sigma) + diag 
  theta <- sigma + 0.5 * diag(p)
  sigma <- pinv(theta)
  return(list("Theta"=theta,"Sigma"=sigma))
}

# Minimal working example
p <- 5
res <- genThetaSigma(p)

```

Use glasso package to compute the TPR and FPR for different values of rho on one graph

```{r pressure, echo=FALSE}
experiment <-function(p,n,lrho,thr=0.0001){
  
  # Normalize rho
  lrho <- lrho / p
  
  # Generate mu
  mu = runif(p,-1,1)
  # Generate sigma (and the corresponding theta)
  res <- genThetaSigma(p)
  sigma <- res$Sigma
  theta <- res$Theta
  
  # Generate a sample
  X = mvrnorm(n, mu, sigma)
  
  # Empirical covariance
  S <- cov(X)
  
  # Run graphical lasso
  gp <- glassopath(S,lrho,trace=0)
  
  # A coeff is considered null if its absolue value is below thr
  
  # Counts the number of null coefficients
  count_P <- function(m){sum(abs(m) < thr)}
  # Counts the number of non null coefficients
  count_N <- function(m){sum(abs(m)>=thr)}
  # Outputs the number of true positive coefficients
  count_TP <- function(m){sum((abs(m) < thr)&(abs(theta) < thr))}
  # Outputs the number of false positive coefficients
  count_FP <- function(m){sum((abs(m) < thr)&(abs(theta) > thr))}
  
  # Counts the number of null coefficients for each wi (inverse of w, i.e. theta)
  res_P <- apply(gp$wi,3,count_P)
  # Counts the number of true positives for each wi
  res_TP <- apply(gp$wi,3,count_TP)
  # Counts the number of false positives for each wi
  res_FP <- apply(gp$wi,3,count_FP)

  # Compute the true positive rate
  rate_true <- res_TP / max(1, count_P(theta))
  # Compute the false positive rate
  rate_false <- res_FP / max(1, count_N(theta)-p)
  
  return(cbind(lrho, rate_true, rate_false))
}

# Minimal working example
# Plot test results
p <- 10
n <- 1000
lrho <- unique(c(seq(0.01,0.8,0.05),seq(0.8,10,0.3)))
test_res <- experiment(p,n,lrho)
plot(test_res[,3],test_res[,2],xlim=0:1,ylim=0:1,asp=1,xlab="False positive rate",ylab="True positive rate")
lines(c(0, 1), c(0, 1))
title("ROC curve for a test example")
```

Repeat the experiment on N different graphs

```{r, echo=FALSE}
# Repeat experiment a given number of times N and compute statistics
N <- 100

# Experimental setup
p <- 10
n <- 1000
lrho <- unique(c(seq(0.01,0.8,0.05),seq(0.8,10,0.3)))

# Print to eps?
print_to_eps <- FALSE

rate_true_list <- list()
rate_false_list <- list()

# Repeat experiment N times
for(i in 1:N) {
  test_res <- experiment(p,n,lrho)
  rate_true_list <- cbind(rate_true_list,test_res[,2])
  rate_false_list <- cbind(rate_false_list,test_res[,3])
}

rate_true_list <- matrix(unlist(rate_true_list), byrow=FALSE, ncol=N)
rate_false_list <- matrix(unlist(rate_false_list), byrow=FALSE, ncol=N)

# Compute means and quantiles
means_T <- apply(rate_true_list, 1, mean)
quant10_T <- apply(rate_true_list, 1, function(m){return(quantile(m, probs=0.1))})
quant90_T <- apply(rate_true_list, 1, function(m){return(quantile(m, probs=0.9))})
means_F <- apply(rate_false_list, 1, mean)
quant10_F <- apply(rate_false_list, 1, function(m){return(quantile(m, probs=0.1))})
quant90_F <- apply(rate_false_list, 1, function(m){return(quantile(m, probs=0.9))})

# Plot with uncertainty bars
if(print_to_eps){
  setEPS()
  postscript("experiment_random_graphs.eps")
}
par(pty="s")
plot(0,type='n',xlim=0:1,ylim=0:1,asp=1,xlab="False positive rate",ylab="True positive rate",cex.lab=1.1)
segments(means_F,quant10_T,means_F,quant90_T, col="#00ccff")
segments(quant10_F,means_T,quant90_F,means_T, col="#00ccff")
epsilon <- 0.01
segments(means_F-epsilon,quant10_T,means_F+epsilon,quant10_T, col="#00ccff")
segments(means_F-epsilon,quant90_T,means_F+epsilon,quant90_T, col="#00ccff")
segments(quant10_F,means_T-epsilon,quant10_F,means_T+epsilon, col="#00ccff")
segments(quant90_F,means_T-epsilon,quant90_F,means_T+epsilon, col="#00ccff")
# lines(quant10_F, means_T)
# lines(quant90_F, means_T)
# lines(means_F, quant10_T)
# lines
points(means_F,means_T)
lines(c(0, 1),c(0, 1))
chosen_labels <- c(1,2,seq(3,17,2),18)
text(means_F[chosen_labels],means_T[chosen_labels]+0.04,labels=lrho[chosen_labels],cex=0.9)
title("ROC curve, N=100 (p=10, n=1000), for different values of rho",cex.main=1.2)

if(print_to_eps){
  dev.off()
}
```

Compute the theoretical rho as in Banerjee et al. (2008)

```{r}
# Repeat the experiment N times

p <- 10
n <- 100
alpha <- seq(0.01,0.9,0.05)

trho_list <- list()

for(i in 1:N){
  mu = runif(p,-1,1)
  res <- genThetaSigma(p)
  sigma <- res$Sigma
  # Generate a sample
  X = mvrnorm(n, mu, sigma)
  # Empirical covariance
  S <- cov(X)
  
  # Compute the max products of variances
  S <- matrix(unlist(diag(S)),ncol=1)
  var_products <- S %*% t(S)
  for(i in 1:p){
    var_products[i, 1:i] = 0
  }
  max_var_products <- max(max(var_products))
  
  # Compute the theoretical rho
  trho <- max_var_products * qt(1-alpha/(2*p*p), n-2) / sqrt(n-2+(qt(1-alpha/(2*p*p), n-2))**2)
  trho_list <- cbind(trho_list, trho)
}

trho_matrix <- matrix(unlist(trho_list), byrow=FALSE, ncol=N)
trho_means <- apply(trho_matrix, 1, mean)
trho_quant10 <- apply(trho_matrix, 1, function(m){return(quantile(m, probs=0.1))})
trho_quant90 <- apply(trho_matrix, 1, function(m){return(quantile(m, probs=0.9))})

print(cbind(alpha,trho_quant10,trho_means,trho_quant90))
```

Generate a Markov chain

```{r}
genMarkov <- function(p){
theta <- eye(p)
for (i in 2:p){
  theta[i-1,i] = 0.5
  theta[i,i-1] = 0.5
}
theta <-as.matrix(theta)
sigma <- pinv(theta)
res = list("Theta"=theta,"Sigma"=sigma)
return(res)
}

```


# Markov chain experiment

The goal is to test whether the lasso algorithm can reconstruct a Markov chain model based on experimental data.


Compute the number of connected components


```{r}
num_connected_components <- function(M,thre=0.0001){
  p <- dim(M)[1]
  N <- matrix(0,p,p)
  for (i in 1:p){
    for (j in 1:p){
      if (abs(M[i,j])>thre){
        N[i,j]=1
        N[j,i]=1
      }
    }
  }
  E = expm(N)
  for (i in 1:p){
    for (j in 1:p){
      if (abs(E[i,j])>thre){
        E[i,j]=1
      }
    }
  }
  if (rowSums(E)[1]!=p){
    a <- 2
  }
  else {a<-1}
  return(a)
}
```


Experiment on the Markov chain and say whether the graph is connected

```{r}
experiment_markov <-function(p,n,lrho,thr=0.001){
  
  # Normalize rho
  lrho <- lrho 
  
  # Generate mu
  mu = runif(p,-1,1)
  # Generate sigma (and the corresponding theta)
  res <- genMarkov(p)
  
  theta <- res$Theta
  sigma <- res$Sigma
  # Generate a sample
  X = mvrnorm(n, mu, sigma)
  
  # Empirical covariance
  S <- cov(X)
  
  # Run graphical lasso
  gp <- glassopath(S,lrho,trace=0)
  

  # For each wi, is the graph connected?
  ncomp <- apply(gp$wi,3,num_connected_components)
  W <-gp$wi
  d <- dim(W)
  a <- d[1]
  b <- d[2]
  c <- d[3]
  for (i in 1:a){
    for (j in 1:b){
      for (k in 1:c){
        if (abs(W[i,j,k])< thr){W[i,j,k]=0}
      }
    }
  }
  
  # Compute the max products of variances
  alpha <- seq(0.0001,0.005,0.001)
S <- matrix(unlist(diag(S)),ncol=1)
var_products <- S %*% t(S)
for(i in 1:p){
  var_products[i, 1:i] = 0
}
max_var_products <- max(max(var_products))

# Compute the theoretical rho
trho <- max_var_products * qt(1-alpha/(2*p*p), n-2) / sqrt(n-2+(qt(1-alpha/(2*p*p), n-2))**2)
rho_theo <-(cbind(alpha,trho))
  
  return(list("res"=cbind(lrho, ncomp),"WI"=W,"rho_theo"=rho_theo))
}
```


Test


```{r}
p <- 10
n <- 10000
lrho <- c(seq(0.001,2,0.05))
res<-experiment_markov(p,n,lrho)
setEPS()
postscript("connected_components.eps")
plot(res$res[,1],res$res[,2], 
  xlab="rho", ylab=" ",yaxp  = c(1, 2, 1),pin=c(500,100))

dev.off()
plot(res$res[,1],res$res[,2], main="Number of connected components of the graph",
  xlab="rho", ylab=" ",yaxp  = c(1, 2, 1),pin=c(500,200))

ind <- 1
for (i in 1:dim(res$res)[1]){
  if (res$res[i,2]==1){
  ind <- i
  }
}
print(lrho[ind])
print(res$rho_theo)
```


Graph in function of rho


```{r}
experiment_markov2 <-function(p,n,lrho,thr=0.001){
  
  # Normalize rho
  lrho <- lrho 
  
  # Generate mu
  mu = runif(p,-1,1)
  # Generate sigma (and the corresponding theta)
  res <- genMarkov(p)
  
  theta <- res$Theta
  sigma <- res$Sigma
  # Generate a sample
  X = mvrnorm(n, mu, sigma)
  
  # Empirical covariance
  S <- cov(X)
  
  # Run graphical lasso
  gp <- glassopath(S,lrho,trace=0)
  return(gp)
}

```


Test


```{r}
p <- 10
n <- 10000
lrho <- c(seq(0.001,10,0.1))
res<-experiment_markov2(p,n,lrho)
write.csv(res$wi, file = "MyData1.csv")
```


